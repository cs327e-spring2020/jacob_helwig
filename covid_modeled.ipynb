{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.7/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.\n",
      "INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'covid_staging'\n",
      " projectId: 'corvid-276516'\n",
      " tableId: 'googleMobility'> referenced by query SELECT * FROM covid_staging.googleMobility ORDER BY date, country_region limit 100\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset corvid-276516:temp_dataset_2d0a5725b04d4d0b82f3e04680a72802 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table corvid-276516.covid_modeled.mobility_beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'code'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'country'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'date'\n",
      " type: 'DATE'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'average_change'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'retail_and_recreation'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'grocery_and_pharmacy'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'parks'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'transit_stations'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'workplaces'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'residential'\n",
      " type: 'INTEGER'>]>. Result: <Table\n",
      " creationTime: 1588899133772\n",
      " etag: 'bth3MOPaUbVKdtTjzDUMPQ=='\n",
      " id: 'corvid-276516:covid_modeled.mobility_beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1588899133816\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'code'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'country'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'date'\n",
      " type: 'DATE'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'average_change'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'retail_and_recreation'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'grocery_and_pharmacy'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'parks'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'transit_stations'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'workplaces'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'residential'\n",
      " type: 'INTEGER'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/corvid-276516/datasets/covid_modeled/tables/mobility_beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'covid_modeled'\n",
      " projectId: 'corvid-276516'\n",
      " tableId: 'mobility_beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run mobility_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.7/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://covid-bucket19/staging/format-codes--df.1588906237.924080/pipeline.pb...\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 1/2)\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://covid-bucket19/staging/format-codes--df.1588906237.924080/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpnsf26zus', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://covid-bucket19/staging/format-codes--df.1588906237.924080/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://covid-bucket19/staging/format-codes--df.1588906237.924080/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://covid-bucket19/staging/format-codes--df.1588906237.924080/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpnsf26zus', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '37', '--implementation', 'cp', '--abi', 'cp37m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://covid-bucket19/staging/format-codes--df.1588906237.924080/apache_beam-2.19.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://covid-bucket19/staging/format-codes--df.1588906237.924080/apache_beam-2.19.0-cp37-cp37m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://covid-bucket19/staging/format-codes--df.1588906237.924080/apache_beam-2.19.0-cp37-cp37m-manylinux1_x86_64.whl in 0 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-05-08T02:50:42.636284Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-05-07_19_50_41-716779937527363931'\n",
      " location: 'us-central1'\n",
      " name: 'format-codes--df'\n",
      " projectId: 'corvid-276516'\n",
      " stageStates: []\n",
      " startTime: '2020-05-08T02:50:42.636284Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-05-07_19_50_41-716779937527363931]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-05-07_19_50_41-716779937527363931?project=corvid-276516\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-05-07_19_50_41-716779937527363931 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:41.350Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-05-07_19_50_41-716779937527363931. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:41.350Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-05-07_19_50_41-716779937527363931.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:45.529Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:46.489Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-1 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:47.052Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:47.092Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 1/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:47.132Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:47.165Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:47.245Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:47.789Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:47.838Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Change the country code for Greece, the UK, and Hong Kong. Drop Reunion\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:47.873Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WriteBundles/WriteBundles into Change the country code for Greece, the UK, and Hong Kong. Drop Reunion\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:47.899Z: JOB_MESSAGE_DETAILED: Fusing consumer Change the country code for Greece, the UK, and Hong Kong. Drop Reunion into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:47.933Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Pair into Write log 1/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:47.965Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 1/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.005Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Reify into Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.041Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/Write into Write log 1/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.076Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 1/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.112Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/Extract into Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.148Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 1/Write/WriteImpl/InitializeWrite into Write log 1/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.184Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.216Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.250Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.279Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.421Z: JOB_MESSAGE_DEBUG: Executing wait step start16\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.625Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.657Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.668Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.707Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.767Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:50:48.839Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-05-07_19_50_41-716779937527363931 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:51:20.809Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running stage(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:52:57.852Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:52:57.892Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:53:34.521Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/DoOnce/Read+Write log 1/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:53:34.859Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:53:34.969Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:53:35.072Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:53:35.108Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:53:35.144Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:53:35.156Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:53:35.193Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:53:35.225Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:53:35.226Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:53:35.276Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:53:35.315Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:53:35.354Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Change the country code for Greece, the UK, and Hong Kong. Drop Reunion+Write BQ table/WriteToBigQuery/NativeWrite+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:53:37.872Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_16186655479599868533\". You can check its status with the bq tool: \"bq show -j --project_id=corvid-276516 dataflow_job_16186655479599868533\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:54:48.450Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_16186655479599868533\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:54:48.909Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_8975730836680901253\" started. You can check its status with the bq tool: \"bq show -j --project_id=corvid-276516 dataflow_job_8975730836680901253\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:55:19.427Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_8975730836680901253\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:55:19.594Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_8975730836680901253\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:55:56.434Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_16186655479599869490\". You can check its status with the bq tool: \"bq show -j --project_id=corvid-276516 dataflow_job_16186655479599869490\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:07.413Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_16186655479599869490\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:09.392Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Change the country code for Greece, the UK, and Hong Kong. Drop Reunion+Write BQ table/WriteToBigQuery/NativeWrite+Write log 1/Write/WriteImpl/WriteBundles/WriteBundles+Write log 1/Write/WriteImpl/Pair+Write log 1/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 1/Write/WriteImpl/GroupByKey/Reify+Write log 1/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:09.507Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:09.581Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:09.672Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:21.280Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/GroupByKey/Read+Write log 1/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 1/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:21.359Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:21.441Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:21.466Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:21.528Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:21.553Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:21.585Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:21.623Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:21.664Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:28.403Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:28.506Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:28.599Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:28.702Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:28.785Z: JOB_MESSAGE_DEBUG: Value \"Write log 1/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:28.867Z: JOB_MESSAGE_BASIC: Executing operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:32.624Z: JOB_MESSAGE_BASIC: Finished operation Write log 1/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:32.695Z: JOB_MESSAGE_DEBUG: Executing success step success14\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:32.825Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:32.942Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:56:32.976Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:58:39.524Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:58:39.586Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-08T02:58:39.631Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-05-07_19_50_41-716779937527363931 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run mobility_df.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE covid_modeled.geoDist AS\n",
    "SELECT geo_id AS code, countries_and_territories AS country, date, daily_confirmed_cases AS daily_cases, \n",
    "daily_deaths, confirmed_cases AS cases, deaths, ROUND(daily_deaths/(pop_data_2018/100000),5) AS deaths_per_100000, \n",
    "ROUND(daily_confirmed_cases/(pop_data_2018/100000),5) AS cases_per_100000, pop_data_2018 AS pop, cc.continent\n",
    "FROM covid_staging.covidGeoDist\n",
    "LEFT JOIN covid_staging.countryContinent c \n",
    "ON geo_id = country\n",
    "LEFT JOIN covid_staging.contCode cc\n",
    "ON c.continent = code \n",
    "ORDER BY date, country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data flow has been run on googleMobility to transform it to covid_modeled.mobility_beam, there should be referential integrity between the countries in mobility_beam and geoDist. \n",
    "geoDist will be the transformed version of covidGeoDist, with a couple of new calculated fields (deaths per capita and cases per capita), continent, and cleaner columns. \n",
    "Check that code and date form a composite primary key in geoDist. Verify the referential integrity between the two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  15282"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*)\n",
    "FROM covid_modeled.geoDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  15282"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT (*)\n",
    "FROM \n",
    "  (SELECT DISTINCT code, date\n",
    "  FROM covid_modeled.geoDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [code]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT DISTINCT m.code\n",
    "FROM covid_modeled.mobility_beam m\n",
    "WHERE m.code NOT IN \n",
    "  (SELECT g.code \n",
    "  FROM covid_modeled.geoDist g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referential integrity has been verified. Check for a composite primary key in mobility_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f0_\n",
       "0  300747"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*)\n",
    "FROM covid_modeled.mobility_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f0_\n",
       "0  9956"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*)\n",
    "FROM \n",
    "  (SELECT DISTINCT country, date\n",
    "   FROM covid_modeled.mobility_beam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are many duplicate country, date value pairs. How can this be? It is because of the sub_region_1 and sub_region_2 adding a further level of granularity to each country, date pair. Some countries have been divided up further into sub regions. However, geoDist is at the country level. In order to raise mobility_beam to this level, use group by to take an average across the whole country for each date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE covid_modeled.mobility AS\n",
    "SELECT code, country, date, ROUND(AVG(average_change)/100,2) AS average_change, ROUND(AVG(retail_and_recreation)/100,2) AS retail_and_recreation, \n",
    "ROUND(AVG(grocery_and_pharmacy)/100,2) AS grocery_and_pharmacy, ROUND(AVG(parks)/100,2) AS parks, ROUND(AVG(transit_stations)/100,2) AS transit_stations, \n",
    "ROUND(AVG(workplaces)/100,2) AS workplaces, ROUND(AVG(residential)/100,2) AS residential\n",
    "FROM covid_modeled.mobility_beam\n",
    "GROUP BY code, country, date\n",
    "ORDER BY date, country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f0_\n",
       "0  9956"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT (*)\n",
    "FROM covid_modeled.mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f0_\n",
       "0  9956"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*)\n",
    "FROM \n",
    "  (SELECT DISTINCT code, date\n",
    "  FROM covid_modeled.mobility)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m47"
  },
  "kernelspec": {
   "display_name": "Python (beam_venv)",
   "language": "python",
   "name": "beam_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
